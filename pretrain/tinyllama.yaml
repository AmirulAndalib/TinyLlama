model_name: "tinyllama"
name: "visuagestream"
out_dir: "out/visuagestream"
pretrained_path: "checkpoints/openlm-research/open_llama_3b_v2/lit_model.pth"
per_node_global_batch_size: 512
learning_rate: 0.00003
min_lr: 0.000003
micro_batch_size: 4
num_of_devices: 3
max_step: 10000
warmup_steps: 0


log_step_interval: 10
eval_iters: 10
save_step_interval: 5000
eval_step_interval: 1000
weight_decay: 0.1
beta1: 0.9
beta2: 0.95
grad_clip: 1.0
decay_lr: true
resume: false

train_data_dir: 
val_data_dir: 
train_data_config:
  - - "train_slim"
    - 1.0
val_data_config:
  - - "validation"
    - 1.0
seed: 3407